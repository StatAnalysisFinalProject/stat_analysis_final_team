{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1b2543-fef8-469a-8423-af2ee47da17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "# ===== í™˜ê²½ ì„¤ì • =====\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.Client()\n",
    "\n",
    "TOTAL_QUESTIONS = 3\n",
    "\n",
    "SKIP_KEYWORDS = [\n",
    "    \"ë‹¤ìŒ ì§ˆë¬¸\", \"ë‹¤ìŒì§ˆë¬¸\", \"ìŠ¤í‚µ\", \"skip\", \"pass\", \"next\",\n",
    "    \"next question\", \"ë„˜ì–´ê°€ê¸°\", \"ë„˜ì–´ê°€ì\", \"ë„˜ì–´ê°ˆê²Œìš”\"\n",
    "]\n",
    "\n",
    "# íƒœë„/ëª¨ë²”/ì„±ì‹¤ ì¹­ì°¬ë§Œ ì œê±°\n",
    "EXCLUDE_KEYWORDS = [\n",
    "    \"ì„±ì‹¤\", \"ì„±ì‹¤í•¨\", \"ì„±ì‹¤í•˜ê²Œ\", \"ëª¨ë²”\", \"ëª¨ë²”ì ì¸\",\n",
    "    \"íƒœë„\", \"íƒœë„ê°€\", \"ìì„¸ê°€ ì¢‹\", \"ì •ì„±ì„ ë‹¤í•´\",\n",
    "    \"ë°œí‘œí•œ ëª¨ìŠµì´ ë³´ê¸° ì¢‹ì•˜\", \"ë°œí‘œë¥¼ ì˜í•¨\", \"ë°œí‘œë¥¼ ì˜ í•˜\",\n",
    "    \"ì°¸ì—¬ë„ê°€ ë†’\", \"ì—´ì‹¬íˆ ì°¸ì—¬\", \"ì ê·¹ì ìœ¼ë¡œ ì°¸ì—¬\",\n",
    "    \"ì¹œêµ¬ë“¤ê³¼ ì˜ ì§€ë‚´\", \"ë´‰ì‚¬ì •ì‹ ì´ íˆ¬ì² \", \"ì˜ˆì˜ë°”ë¥¸ íƒœë„\"\n",
    "]\n",
    "\n",
    "# í¬ë§ ë¶„ì•¼ ë§¤í•‘\n",
    "CAREER_SUBJECT_MAP = {\n",
    "    \"ê³µí•™\": [\"ìˆ˜í•™\", \"ê¸°í•˜\", \"ë¯¸ì \", \"ë¯¸ì ë¶„\", \"ê³¼í•™\", \"ë¬¼ë¦¬\",\n",
    "           \"ìœµí•©ê³¼í•™\", \"ì •ë³´\", \"í”„ë¡œê·¸ë˜ë°\", \"ê³µí•™\", \"ì¸ê³µì§€ëŠ¥ ìˆ˜í•™\"],\n",
    "    \"ìì—°\": [\"ìƒëª…\", \"ìƒëª…ê³¼í•™\", \"í™”í•™\", \"ì§€êµ¬\", \"ì§€êµ¬ê³¼í•™\", \"ë¬¼ë¦¬\", \"ê³¼í•™\"],\n",
    "    \"ì˜í•™\": [\"ìƒëª…\", \"ìƒëª…ê³¼í•™\", \"í™”í•™\", \"ë³´ê±´\", \"ì˜í•™\"],\n",
    "    \"ì»´í“¨í„°\": [\"ì •ë³´\", \"í”„ë¡œê·¸ë˜ë°\", \"AI\", \"ë°ì´í„°\", \"ìˆ˜í•™\",\n",
    "            \"ê¸°í•˜\", \"ë¯¸ì ë¶„\", \"ì¸ê³µì§€ëŠ¥ ìˆ˜í•™\", \"ì»´í“¨í„°ê³µí•™\"],\n",
    "    \"ì†Œí”„íŠ¸ì›¨ì–´\": [\"ì •ë³´\", \"í”„ë¡œê·¸ë˜ë°\", \"AI\", \"ì»´í“¨í„°\", \"ìˆ˜í•™\"],\n",
    "    \"AI\": [\"ì •ë³´\", \"í”„ë¡œê·¸ë˜ë°\", \"AI\", \"ìœµí•©ê³¼í•™\", \"ìˆ˜í•™\", \"ì¸ê³µì§€ëŠ¥ ìˆ˜í•™\"],\n",
    "    \"ìƒê²½\": [\"ê²½ì œ\", \"ì‚¬íšŒ\", \"ì •ì¹˜\", \"ìˆ˜í•™\", \"í™•ë¥ ê³¼í†µê³„\"],\n",
    "    \"ê²½ì˜\": [\"ê²½ì˜\", \"ê²½ì œ\", \"ì‚¬íšŒ\", \"ìˆ˜í•™\"],\n",
    "    \"ì¸ë¬¸\": [\"êµ­ì–´\", \"ë¬¸í•™\", \"ë…ì„œ\", \"ì‚¬íšŒ\", \"ìœ¤ë¦¬\", \"ì² í•™\"],\n",
    "    \"êµìœ¡\": [\"êµìœ¡\", \"ì‹¬ë¦¬\", \"êµ­ì–´\", \"ì‚¬íšŒ\"]\n",
    "}\n",
    "\n",
    "##########################################################\n",
    "# 1. ì „ì²´ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°\n",
    "##########################################################\n",
    "def get_full_text(student_data):\n",
    "    records = student_data.get(\"academic_records\", [])\n",
    "    if isinstance(records, list):\n",
    "        full = \"\\n\".join(str(x) for x in records)\n",
    "    else:\n",
    "        full = str(records)\n",
    "\n",
    "    reading = student_data.get(\"reading\", \"\")\n",
    "    if reading:\n",
    "        full += \"\\n\" + str(reading)\n",
    "\n",
    "    return full\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 2. í¬ë§ë¶„ì•¼ â†’ í•™ë…„ë³„ ìë™ ë°°ì •\n",
    "##########################################################\n",
    "def extract_career_by_grade(full_text):\n",
    "    matches = re.findall(r\"í¬ë§\\s*ë¶„ì•¼\\s*([^\\n]+)\", full_text)\n",
    "\n",
    "    grade_raw = {1: None, 2: None, 3: None}\n",
    "    for idx, raw in enumerate(matches[:3], start=1):\n",
    "        cleaned = raw.replace(\"ë¶„ì•¼\", \"\").replace(\"ê³„ì—´\", \"\").strip()\n",
    "        grade_raw[idx] = cleaned\n",
    "\n",
    "    def normalize(field):\n",
    "        if not field:\n",
    "            return \"\"\n",
    "        if \"ì»´í“¨í„°\" in field or \"ì†Œí”„íŠ¸ì›¨ì–´\" in field:\n",
    "            return \"ì»´í“¨í„°\"\n",
    "        if \"ai\" in field.lower():\n",
    "            return \"AI\"\n",
    "        if \"ê³µí•™\" in field:\n",
    "            return \"ê³µí•™\"\n",
    "        if \"ìì—°\" in field:\n",
    "            return \"ìì—°\"\n",
    "        if \"ì˜í•™\" in field:\n",
    "            return \"ì˜í•™\"\n",
    "        if \"ê²½ì˜\" in field:\n",
    "            return \"ê²½ì˜\"\n",
    "        if \"ìƒê²½\" in field:\n",
    "            return \"ìƒê²½\"\n",
    "        if \"ì¸ë¬¸\" in field:\n",
    "            return \"ì¸ë¬¸\"\n",
    "        if \"êµìœ¡\" in field:\n",
    "            return \"êµìœ¡\"\n",
    "        return field\n",
    "\n",
    "    grade_norm = {g: normalize(v) for g, v in grade_raw.items()}\n",
    "    return grade_raw, grade_norm\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 3. ì„¸íŠ¹/ì°½ì²´ ì¶œì²˜ ìë™ ì¶”ì¶œ\n",
    "##########################################################\n",
    "def extract_sources(full_text):\n",
    "    sources = []\n",
    "\n",
    "    # 3-1) ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­\n",
    "    pattern = re.compile(\n",
    "        r\"([ê°€-í£A-Za-z0-9\\s]+):\\s*(.+?)(?=\\n[ê°€-í£A-Za-z0-9\\s]+:|\\në™ì•„ë¦¬í™œë™|\\nììœ¨í™œë™|\\nì§„ë¡œí™œë™|\\në´‰ì‚¬í™œë™|\\Z)\",\n",
    "        re.DOTALL\n",
    "    )\n",
    "\n",
    "    for m in pattern.finditer(full_text):\n",
    "        subject = m.group(1).strip()\n",
    "        desc = m.group(2).strip().replace(\"\\n\", \" \")[:250]\n",
    "        label = f\"{subject}(ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­)\"\n",
    "        sources.append((label, desc))\n",
    "\n",
    "    # 3-2) ì°½ì²´\n",
    "    blocks = [\"ë™ì•„ë¦¬í™œë™\", \"ììœ¨í™œë™\", \"ì§„ë¡œí™œë™\", \"ë´‰ì‚¬í™œë™\"]\n",
    "    for b in blocks:\n",
    "        bpat = re.compile(\n",
    "            b + r\"\\s*\\n(.+?)(?=\\në™ì•„ë¦¬í™œë™|\\nììœ¨í™œë™|\\nì§„ë¡œí™œë™|\\në´‰ì‚¬í™œë™|\\Z)\",\n",
    "            re.DOTALL\n",
    "        )\n",
    "        for m in bpat.finditer(full_text):\n",
    "            desc = m.group(1).strip().replace(\"\\n\", \" \")[:250]\n",
    "            sources.append((b, desc))\n",
    "\n",
    "    return sources\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 4. íƒœë„ì„± ë‚´ìš© ì œê±°\n",
    "##########################################################\n",
    "def filter_out_attitude(sources):\n",
    "    clean = []\n",
    "    for label, text in sources:\n",
    "        combo = label + \" \" + text\n",
    "        if not any(bad in combo for bad in EXCLUDE_KEYWORDS):\n",
    "            clean.append((label, text))\n",
    "    return clean\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 5. label â†’ ê³¼ëª©ëª…/í™œë™ì¢…ë¥˜ ë¶„ë¦¬\n",
    "##########################################################\n",
    "def split_label(label):\n",
    "    \"\"\"\n",
    "    label ì˜ˆ:\n",
    "    - 'ì¸ê³µì§€ëŠ¥ ìˆ˜í•™(ì„¸ë¶€ëŠ¥ë ¥íŠ¹ê¸°ì‚¬í•­)'\n",
    "    - 'ë™ì•„ë¦¬í™œë™'\n",
    "    \"\"\"\n",
    "    if \"(\" in label:\n",
    "        subject = label.split(\"(\")[0]\n",
    "        activity = label[label.find(\"(\")+1:-1]\n",
    "    else:\n",
    "        subject = label\n",
    "        activity = \"ì°½ì²´í™œë™\"\n",
    "\n",
    "    return subject.strip(), activity.strip()\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# 6. ë©”ì¸ ë¡œì§\n",
    "##########################################################\n",
    "def start_ai_interview(student_data):\n",
    "    full_text = get_full_text(student_data)\n",
    "\n",
    "    # --- í¬ë§ë¶„ì•¼ ì¶”ì¶œ ---\n",
    "    career_raw, career_norm = extract_career_by_grade(full_text)\n",
    "\n",
    "    print(\"\\n=== í¬ë§ë¶„ì•¼ ì¸ì‹ ê²°ê³¼ ===\")\n",
    "    for g in [1,2,3]:\n",
    "        print(f\"{g}í•™ë…„ â†’ {career_raw.get(g)} (í‚¤ì›Œë“œ: {career_norm.get(g)})\")\n",
    "    print(\"==========================\\n\")\n",
    "\n",
    "    # --- ì¶œì²˜ ì¶”ì¶œ ---\n",
    "    sources = extract_sources(full_text)\n",
    "    sources = filter_out_attitude(sources)\n",
    "\n",
    "    if not sources:\n",
    "        print(\"ì¶œì²˜ ì—†ìŒ. JSON êµ¬ì¡° í™•ì¸ í•„ìš”.\")\n",
    "        return\n",
    "\n",
    "    # --- A ëª¨ë“œ SYSTEM PROMPT ---\n",
    "    system_prompt = '''\n",
    "ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ìµœìƒìœ„ê¶Œ ê³µëŒ€ ë©´ì ‘ê´€ì´ë‹¤.\n",
    "ë§¤ìš° ëƒ‰ì •í•˜ê³  ë‚ ì¹´ë¡­ê²Œ í‰ê°€í•˜ë©° ìƒê¸°ë¶€ì™€ ë¬´ê´€í•œ ë‹µë³€ì€ ëª¨ë‘ í˜¹í‰í•˜ë¼.\n",
    "ì ìˆ˜ < 70ì ì´ë©´ ë°˜ë“œì‹œ [ë‹¤ì‹œ ë‹µë³€ ìš”ì²­]ì„ ë¶™ì¸ë‹¤.\n",
    "'''\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    question_num = 1\n",
    "\n",
    "    while question_num <= TOTAL_QUESTIONS:\n",
    "\n",
    "        # === 1) í•™ë…„ ëœë¤ ì„ íƒ ===\n",
    "        selected_grade = random.choice([1,2,3])\n",
    "        selected_career_raw = career_raw[selected_grade]\n",
    "        selected_career_norm = career_norm[selected_grade]\n",
    "\n",
    "        # === 2) í•´ë‹¹ í•™ë…„ í¬ë§ë¶„ì•¼ ê¸°ë°˜ í•„í„° ===\n",
    "        allowed_keywords = CAREER_SUBJECT_MAP.get(selected_career_norm, [])\n",
    "        grade_sources = [\n",
    "            s for s in sources if any(k in (s[0] + s[1]) for k in allowed_keywords)\n",
    "        ]\n",
    "        if not grade_sources:\n",
    "            grade_sources = sources\n",
    "\n",
    "        # === 3) ì¶œì²˜ ì„ íƒ ===\n",
    "        label, text = random.choice(grade_sources)\n",
    "        subject_name, activity_type = split_label(label)\n",
    "\n",
    "        is_last = (question_num == TOTAL_QUESTIONS)\n",
    "\n",
    "        # === 4) ì§ˆë¬¸ ìƒì„± ===\n",
    "        user_prompt = f'''\n",
    "ë‹¤ìŒ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ {\"[ë§ˆì§€ë§‰ ì§ˆë¬¸]\" if is_last else \"[ì§ˆë¬¸]\"}ì„ ìƒì„±í•˜ë¼.\n",
    "\n",
    "ì¶œì²˜ í•™ë…„: {selected_grade}í•™ë…„\n",
    "ê³¼ëª©ëª…: {subject_name}\n",
    "í™œë™ì¢…ë¥˜: {activity_type}\n",
    "ì¶œì²˜ ì „ë¬¸: {label}\n",
    "í•µì‹¬ ë‚´ìš©: {text}\n",
    "\n",
    "í•´ë‹¹ í•™ë…„ í¬ë§ë¶„ì•¼: {selected_career_raw} (í‚¤ì›Œë“œ: {selected_career_norm})\n",
    "\n",
    "í˜•ì‹:\n",
    "{\"[ë§ˆì§€ë§‰ ì§ˆë¬¸]\" if is_last else \"[ì§ˆë¬¸]\"}\n",
    "ì¶œì²˜: {selected_grade}í•™ë…„ Â· {subject_name} ({activity_type})\n",
    "í¬ë§ë¶„ì•¼({selected_grade}í•™ë…„): {selected_career_raw}\n",
    "í•µì‹¬ ë‚´ìš©: {text}\n",
    "ì§ˆë¬¸:\n",
    "'''\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=600\n",
    "        )\n",
    "        qtext = resp.choices[0].message.content\n",
    "        print(\"\\n\" + qtext)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": qtext})\n",
    "\n",
    "        # === 5) ë‹µë³€ ë°›ê¸° ===\n",
    "        answer = input(\"\\n[í•™ìƒ ë‹µë³€ ë˜ëŠ” 'ë‹¤ìŒ ì§ˆë¬¸'] > \")\n",
    "\n",
    "        if any(k in answer.lower() for k in SKIP_KEYWORDS):\n",
    "            print(\"\\n[ì•ˆë‚´] ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\\n\")\n",
    "            question_num += 1\n",
    "            continue\n",
    "\n",
    "        if answer.lower() in (\"exit\", \"quit\"):\n",
    "            print(\"ë©´ì ‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break\n",
    "\n",
    "        # === 6) í‰ê°€ ===\n",
    "        eval_prompt = f'''\n",
    "[í•™ìƒ ë‹µë³€]\n",
    "{answer}\n",
    "\n",
    "ì¶œì²˜ í•™ë…„: {selected_grade}í•™ë…„\n",
    "ê³¼ëª©ëª…: {subject_name}\n",
    "í™œë™ì¢…ë¥˜: {activity_type}\n",
    "ì¶œì²˜ ì „ë¬¸: {label}\n",
    "í•µì‹¬ ë‚´ìš©: {text}\n",
    "í¬ë§ë¶„ì•¼({selected_grade}í•™ë…„): {selected_career_raw}\n",
    "\n",
    "A ëª¨ë“œë¡œ ë§¤ìš° ë‚ ì¹´ë¡­ê²Œ í‰ê°€í•˜ë¼.\n",
    "'''\n",
    "        messages.append({\"role\": \"user\", \"content\": eval_prompt})\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            max_tokens=900\n",
    "        )\n",
    "        eval_text = resp.choices[0].message.content\n",
    "        print(\"\\n\" + eval_text)\n",
    "        messages.append({\"role\": \"assistant\", \"content\": eval_text})\n",
    "\n",
    "        if \"[ë‹¤ì‹œ ë‹µë³€ ìš”ì²­]\" in eval_text:\n",
    "            continue\n",
    "\n",
    "        question_num += 1\n",
    "\n",
    "\n",
    "##########################################################\n",
    "# ì‹¤í–‰\n",
    "##########################################################\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    files = [\n",
    "        f for f in os.listdir(RECORDINGS_DIR)\n",
    "        if f.endswith(\".json\")\n",
    "    ]\n",
    "\n",
    "    if not files:\n",
    "        print(\"âŒ recordings í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        exit()\n",
    "\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(RECORDINGS_DIR, filename)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"ğŸ¯ ë©´ì ‘ ì‹œì‘: {filename}\")\n",
    "        print(\"=\" * 70)\n",
    "\n",
    "        try:\n",
    "            with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "                student_data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {filename} ({e})\")\n",
    "            continue\n",
    "\n",
    "        # í•™ìƒ ì´ë¦„ ì¶œë ¥ (ìˆì„ ê²½ìš°)\n",
    "        name = student_data.get(\"student_info\", {}).get(\"name\", \"ì´ë¦„ ë¯¸ìƒ\")\n",
    "        print(f\"ğŸ‘¤ í•™ìƒ ì´ë¦„: {name}\\n\")\n",
    "\n",
    "        start_ai_interview(student_data)\n",
    "\n",
    "        print(\"\\nâœ… í•´ë‹¹ í•™ìƒ ë©´ì ‘ ì¢…ë£Œ\\n\")\n",
    "\n",
    "        # í•™ìƒ ì‚¬ì´ êµ¬ë¶„ìš© (ì„ íƒ)\n",
    "        cmd = input(\"ğŸ‘‰ ë‹¤ìŒ í•™ìƒìœ¼ë¡œ ì§„í–‰í•˜ë ¤ë©´ Enter (ì¢…ë£Œ: exit) > \")\n",
    "        if cmd.lower() in (\"exit\", \"quit\"):\n",
    "            print(\"ì „ì²´ ë©´ì ‘ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
